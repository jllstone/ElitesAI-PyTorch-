## 过拟合、欠拟合及其解决方案

### 相关概念

> 训练误差（training error）：模型在训练数据集上表现出的误差
>
> 泛化误差（generalization error）：模型在任意一个测试数据样本上表现出的误差的期望，并常常通过测试数据集上的误差来近似。
>
> 机器学习模型应关注降低泛化误差。
>
> 训练集 ≈ 习题集
>
> 验证集 ≈ 模拟考试
>
> 测试集 ≈ 高考

### 过拟合、欠拟合

**欠拟合**（underfitting）：模型无法得到较低的训练误差

**过拟合**（overfitting）：训练误差较低但是泛化误差依然较高，二者相差较大

虽然有很多因素可能导致这两种拟合问题，在这里我们重点讨论两个因素：**模型复杂度**和**训练数据集大小**

- **模型复杂度**

给定训练数据集，模型复杂度和误差之间的关系：

![Image Name](https://cdn.kesci.com/upload/image/q5jc27wxoj.png?imageView2/0/w/960/h/960)

- **训练数据集大小**

一般来说，数据少，参数多，容易发生过拟合
此外，泛化误差不会随训练数据集里样本数量增加而增大。
因此，在计算资源允许的范围之内，我们通常希望训练数据集大一些，特别是在模型复杂度较高时，例如层数较多的深度学习模型。

### 过拟合的解决方案

- **权重衰减**

权重衰减等价于L2范数正则化（regularization）。
正则化通过为模型损失函数添加惩罚项使学出的模型参数值较小，是应对`过拟合`的常用手段。
权重衰减通过惩罚绝对值较大的模型参数，为需要学习的模型增加了限制，这可能对过拟合有效。

**PyTorch简洁实现**

```python
torch.optim.SGD(params=[net.weight], lr=lr, weight_decay=wd) # 对权重参数衰减
```

- **丢弃法**

  ![Image Name](https://cdn.kesci.com/upload/image/q5jd69in3m.png?imageView2/0/w/960/h/960)

对该隐藏层使用丢弃法时，该层的隐藏单元将有一定概率被丢弃掉。设丢弃概率为p，那么有p的概率隐藏单元hi会被清零，有1-p的概率隐藏单元hi会除以1-p做拉伸。丢弃概率是丢弃法的超参数。

丢弃法在训练模型时起到正则化的作用，并可以用来应对`过拟合`。

在反向传播时，被隐藏的神经单元相关权重的梯度均为0

在测试模型时，我们为了拿到更加确定性的结果，一般不使用丢弃法

**PyTorch简洁实现**

```python
net = nn.Sequential(        
    d2l.FlattenLayer(),        
    nn.Linear(num_inputs, num_hiddens1),        
    nn.ReLU(),        
    nn.Dropout(drop_prob1),        
    nn.Linear(num_hiddens1, num_hiddens2),         
    nn.ReLU(),        
    nn.Dropout(drop_prob2),        
    nn.Linear(num_hiddens2, 10)        
	)
```

## 梯度消失、梯度爆炸

### 相关概念

深度模型有关**数值稳定性**的典型问题是`消失（vanishing）`和`爆炸（explosion）`。
当神经网络的`层数较多`时，模型的数值稳定性容易变差。

通常需要随机初始化模型参数。如果将每个隐藏单元的参数都初始化为相等的值，那么在正向传播时每个隐藏单元将根据相同的输入计算出相同的值，并传递至输出层。

在反向传播中，每个隐藏单元的参数梯度值相等。因此，这些参数在使用基于梯度的优化算法迭代后值依然相等。之后的迭代也是如此。

在这种情况下，无论隐藏单元有多少，隐藏层本质上只有1个隐藏单元在发挥作用。因此通常将神经网络的模型参数，特别是权重参数，进行随机初始化。

### 考虑环境因素

- **协变量偏移**

**输入**的分布可能随`时间`而**改变**，但是**标记函数**，即条件分布P(y∣x)**不会改变**。虽然这个问题容易理解，但在实践中也容易忽视。

以区分猫和狗为例，我们的**训练**数据使用的是猫和狗的真实的照片，但是**在测试时**，我们被要求对猫和狗的卡通图片进行分类。

统计学家称这种协变量变化是因为问题的根源在于`特征分布的变化`（即协变量的变化）。
数学上，我们可以说P(x)改变了，但P(y∣x)保持不变。

协变量偏移可以简单理解为：训练集与测试集的`类属`不一致?

- **标签偏移**

当我们认为导致偏移的是标签P(y)上的边缘分布的变化，但类条件分布是不变的P(x∣y)。

如训练数据集，数据很少只包含流感p(y)的样本。而测试数据集有流感p(y)和流感q(y)，其中不变的是流感症状p(x|y)。

标签偏移可以简单理解为：测试时出现了训练时没有的`标签`。

- **概念偏移**

即标签本身的定义发生变化的情况。这听起来很奇怪，毕竟猫就是猫。

的确，猫的定义可能不会改变，但我们能不能对软饮料也这么说呢？事实证明，如果我们周游美国，按地理位置转移数据来源，我们会发现，即使是"软饮料"这个简单术语的定义也会发生相当大的概念转变。![Image Name](https://cdn.kesci.com/upload/image/q5jgd81pl3.png?imageView2/0/w/640/h/640)

分布P(y∣x)可能因我们的位置而异。

这个问题很难发现。另一个可取之处是P(y∣x)通常只是`逐渐变化`。

可理解为在时间条件下，受多种因素影响，反应在地理空间上。

## 循环神经网络进阶

### GRU

> RNN存在的问题：梯度较容易出现衰减或爆炸（BPTT）
>
> 门控循环神经网络：捕捉时间序列中时间步距离较大的依赖关系
>
> • 重置门有助于捕捉时间序列里短期的依赖关系；
>
> • 更新门有助于捕捉时间序列里长期的依赖关系。
>
> 相比LSTM，使用GRU能够达到相当的效果，并且相比之下更容易进行训练，能够很大程度上提高训练效率，因此很多时候会更倾向于使用GRU。

![img](https://brilliantzhang.github.io/pytorch/2.jpg)

得到ht这一步的操作就是忘记传递下来的ht-1 中的某些维度信息，并加入当前节点输入的某些维度信息。
GRU使用了同一个门控z 就同时可以进行遗忘和选择记忆（LSTM则要使用多个门控）。
遗忘z 和选择1-z 是联动的。对于传递进来的维度信息，会进行选择性遗忘，则遗忘了多少权重 （z），我们就会使用包含当前输入的中所对应的权重进行弥补1-z 。以保持一种”恒定“状态。

### LSTM

> 长短期记忆long short-term memory :
>
> 遗忘门:控制上一时间步的记忆细胞
>
> 输入门:控制当前时间步的输入
>
> 输出门:控制从记忆细胞到隐藏状态
>
> 记忆细胞：⼀种特殊的隐藏状态的信息的流动

![img](https://brilliantzhang.github.io/pytorch/1.jpg)

相比RNN只有一个传递状态ht ，LSTM有两个传输状态，一个ct（cell state），和一个ht（hidden state）。
其中对于传递下去的ct改变得很慢，通常输出的ct是上一个状态传过来的ct-1加上一些数值。
LSTM内部主要有三个阶段：

1. 忘记阶段
   这个阶段主要是对上一个节点传进来的输入进行选择性忘记。具体来说是通过计算得到的zf（f表示forget）来作为忘记门控，来控制上一个状态哪些需要留哪些需要忘。
2. 选择记忆阶段
   这个阶段将这个阶段的输入有选择性地进行“记忆”。主要是会对输入进行选择记忆。哪些重要则着重记录下来，哪些不重要，则少记一些。而选择的门控信号则是由zi（i代表information）来进行控制。
3. 输出阶段
   这个阶段将决定哪些将会被当成当前状态的输出。主要是通过zo 来进行控制的。

### RNN参数设置

```python
#深度循环神经网络
nn.LSTM(input_size=vocab_size, hidden_size=num_hiddens,num_layers=2)
#双向循环神经网络
nn.GRU(input_size=vocab_size, hidden_size=num_hiddens,bidirectional=True)
```

